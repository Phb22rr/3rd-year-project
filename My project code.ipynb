{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:24.891780Z",
     "start_time": "2024-11-29T01:29:24.885768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import RunManager as rm\n",
    "import RunBuilder as bm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time as time\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ],
   "id": "671df6058f0a6a74",
   "outputs": [],
   "execution_count": 151
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:25.221173Z",
     "start_time": "2024-11-29T01:29:25.209653Z"
    }
   },
   "source": [
    "#CNN Network\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device = \"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(device)\n",
    "        self.out_channels = out_channels  # Store out_channels as an instance variable\n",
    "        conv1_out_channels = (out_channels + in_channels) // 2\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, conv1_out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(conv1_out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        # Initialize fc1 later\n",
    "        self.fc1 = None  # Initialize later based on input size\n",
    "        self.fc2 = nn.Linear(out_channels, 200)  # Adjust output size if needed\n",
    "        self.fc3 = nn.Linear(200, 100)\n",
    "        self.out = nn.Linear(100, 10)  # The input size must match the output of fc2\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = F.max_pool2d(t, kernel_size=3, stride=2, padding=1)\n",
    "        #print(t.shape)\n",
    "        t = self.conv1(t)\n",
    "        #print(t.shape)\n",
    "        t = F.relu(t)\n",
    "        t = self.conv2(t)\n",
    "        #print(t.shape)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # Flatten the tensor for fully connected layers\n",
    "        t = t.view(t.size(0), -1)\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(t.size(1), self.out_channels).to(self.device)\n",
    "\n",
    "        # Dynamically set the first linear layer based on the flattened size\n",
    "\n",
    "        t = self.fc1(t)\n",
    "        #print(t.shape, \"fc1\")\n",
    "        t = F.relu(t)\n",
    "        t = self.fc2(t)\n",
    "        #print(t.shape, \"fc2\")\n",
    "        t = F.relu(t)\n",
    "        t = self.fc3(t)\n",
    "        #print(t.shape, \"fc1\")\n",
    "        t = F.relu(t)\n",
    "        t = self.out(t)\n",
    "        #print(t.shape, \"out\")\n",
    "        return t\n"
   ],
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:25.517715Z",
     "start_time": "2024-11-29T01:29:25.514199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random data example usage\n",
    "#network = Down(1, 5).to(\"cuda\")\n",
    "#real_samples_labels = torch.randint(0, 100, (1, 1, 32, 32), #dtype=torch.float32).to(\"cuda\")\n",
    "#out = network(real_samples_labels)\n",
    "##print(out.shape)  # Should output: torch.Size([1, 10])\n",
    "\n",
    "#plt.imshow(out[:,:].detach().cpu().numpy())  # get the graph"
   ],
   "id": "9c0fea267d45de36",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:25.827269Z",
     "start_time": "2024-11-29T01:29:25.792206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Download FMNIST data\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()]))"
   ],
   "id": "db23e3eec05341aa",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:26.186227Z",
     "start_time": "2024-11-29T01:29:26.176630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#sample = next(iter(train_set))\n",
    "#image, label = sample # returns a sample, which can be split in to an image and a label\n",
    "#plt.imshow(image.squeeze())"
   ],
   "id": "6e2c347bcffd7971",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:26.811330Z",
     "start_time": "2024-11-29T01:29:26.792291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#first run test\n",
    "#train_loader = torch.utils.data.DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "#sample = next(iter(train_loader))\n",
    "#image, label = sample\n",
    "#print(image.shape)\n",
    "#print(label)\n",
    "#\n",
    "#batch = next(iter(train_loader))\n",
    "#images, labels = batch\n",
    "#images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "#network = Down(in_channels=1, out_channels=100).to(\"cuda\")\n",
    "#preds = network(images)\n",
    "#print(np.max(preds.detach().numpy(),axis=0))\n",
    "#print(preds)\n",
    "#print(labels)"
   ],
   "id": "5cad05b8b586dac8",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:27.139898Z",
     "start_time": "2024-11-29T01:29:27.135881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##first fun test\n",
    "#def get_num_correct(preds, labels):\n",
    "#    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "#\n",
    "#hold = []\n",
    "#for I in range(100):\n",
    "#    batch = next(iter(train_loader))\n",
    "#    images, labels = batch\n",
    "#    images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "#    preds = network(images)\n",
    "#    hold.append(get_num_correct(preds, labels))"
   ],
   "id": "c1b10b372091ad50",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:27.422898Z",
     "start_time": "2024-11-29T01:29:27.415885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#plt.plot(hold)\n",
    "#print(np.mean(hold))"
   ],
   "id": "e1f5f2506c7d4798",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:27.658308Z",
     "start_time": "2024-11-29T01:29:27.648793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#train_loader = torch.utils.data.DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "#sample = next(iter(train_loader))\n",
    "#image, label = sample\n",
    "##print(image.shape)\n",
    "##print(label)#\n",
    "#\n",
    "#def get_num_correct(preds, labels):\n",
    "#    return preds.argmax(dim=1).eq(labels).sum().item()#\n",
    "#\n",
    "#device = torch.device(\"cuda\")\n",
    "#network = Down(1, 16).to(\"cuda\")\n",
    "\n",
    "#batch = next(iter(train_loader))\n",
    "#images, labels = batch\n",
    "#images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#number_run = 100\n",
    "#holdall = np.zeros(number_run)\n",
    "#\n",
    "#optimizer = optim.Adam(network.parameters(), lr=0.01)#, weight_decay=1e-5)#\n",
    "#\n",
    "#for I in range(number_run):\n",
    "#    preds = network(images)\n",
    "#    loss = F.cross_entropy(preds, labels)\n",
    "#    holdall[I] = get_num_correct(preds.to('cuda'), labels.to('cuda'))\n",
    "#    loss.backward() # Calculating the gradients\n",
    "#    #optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "#    optimizer.step()\n",
    "#    optimizer.zero_grad()\n",
    "#plt.plot(holdall)\n",
    "#plt.show()\n",
    "#max_value = holdall.max()\n",
    "#print(max_value)"
   ],
   "id": "e0ad4eb52c0edca0",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:27.953293Z",
     "start_time": "2024-11-29T01:29:27.944777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#training on repeat\n",
    "#histogram = []\n",
    "#\n",
    "#for I in range(100):\n",
    "#    train_loader = torch.utils.data.DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "#    sample = next(iter(train_loader))\n",
    "#    image, label = sample\n",
    "#    #print(image.shape)\n",
    "#    #print(label)#\n",
    "#\n",
    "#    def get_num_correct(preds, labels):\n",
    "#        return preds.argmax(dim=1).eq(labels).sum().item()#\n",
    "#\n",
    "#    device = torch.device(\"cuda\")\n",
    "#    network = Down(1, 16).to(\"cuda\")#\n",
    "#\n",
    "#    batch = next(iter(train_loader))\n",
    "#    images, labels = batch\n",
    "#    images, labels = images.to(device), labels.to(device)#\n",
    "#\n",
    "#    number_run = 500\n",
    "#    holdall = np.zeros(number_run)#\n",
    "#\n",
    "#    optimizer = optim.Adam(network.parameters(), lr=0.01)#, weight_decay=1e-5)##\n",
    "#\n",
    "#    for I in range(number_run):\n",
    "#        preds = network(images)\n",
    "#        loss = F.cross_entropy(preds, labels)\n",
    "#        holdall[I] = get_num_correct(preds.to('cuda'), labels.to('cuda'))\n",
    "#        loss.backward() # Calculating the gradients\n",
    "#        #optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "#        optimizer.step()\n",
    "#        optimizer.zero_grad()#\n",
    "#\n",
    "    #plt.plot(holdall)\n",
    "    #plt.show()\n",
    "    #print(max(holdall))\n",
    "\n",
    "#    histogram.append(max(holdall))\n",
    "#\n",
    "#plt.hist(histogram)\n",
    "#plt.xlabel('Number of correct guesses out of 1000')\n",
    "#plt.ylabel('Frequency (totaling 100)')\n",
    "#plt.title(\"Histogram of the accuracy of the network for 1000 images for 500 runs\")\n",
    "#plt.show()"
   ],
   "id": "6c249c6b391abaca",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:28.388645Z",
     "start_time": "2024-11-29T01:29:28.366089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#run builder and run manager\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "        return runs\n",
    "\n",
    "#run manager\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "\n",
    "    def begin_run(self, run, network, loader):\n",
    "        self.run_start_time = time.time()\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "        characteristics, labels = next(iter(self.loader))\n",
    "\n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "\n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "    def track_loss(self, loss, batch):\n",
    "        self.epoch_loss += loss.item() * batch[0].shape[0]\n",
    "\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "\n",
    "    def inform(self, discrete_n):\n",
    "        if self.epoch_count % discrete_n == 0:\n",
    "            print(self.epoch_count, ' ', self.run_count)"
   ],
   "id": "d33c87d2084424fd",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:28.950787Z",
     "start_time": "2024-11-29T01:29:28.941265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#train manager builder\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "def sanitize_for_windows_path(name):\n",
    "    # Replace invalid characters with underscores or remove them\n",
    "    invalid_chars = r'<>:\"/\\\\|?*'\n",
    "    return ''.join('_' if c in invalid_chars else c for c in name)\n",
    "\n",
    "#train_loader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True, pin_memory=True)\n",
    "\n",
    "params = OrderedDict(lr=[0.0151], batch_size=[36], number_epocs=[1], op=[torch.optim.AdamW])\n",
    "\n",
    "m = rm.RunManager()\n",
    "b = bm.RunBuilder.get_runs(params)\n",
    "\n",
    "for run in b:\n",
    "    print(run)"
   ],
   "id": "60845edbfb29e690",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(lr=0.0151, batch_size=36, number_epocs=1, op=<class 'torch.optim.adamw.AdamW'>)\n"
     ]
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:29:38.865930Z",
     "start_time": "2024-11-29T01:29:30.187726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#train manager\n",
    "network = Down(1, 16).to(\"cuda\")\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "def calculate_correct(out, labels):\n",
    "    return torch.eq(out.argmax(dim=1), labels).sum().numpy()\n",
    "\n",
    "#rounding to 3sfd function\n",
    "#def round_to_sig_figs(num, sig_figs):\n",
    "#    if num == 0:\n",
    "#        return 0\n",
    "#    from math import log10, floor\n",
    "#    return round(num, sig_figs - int(floor(log10(abs(num)))) - 1)\n",
    "\n",
    "#time42 = []\n",
    "max1 = []\n",
    "\n",
    "for run in b:\n",
    "    #u_u = time.time()\n",
    "    network = Down(1, 16).to(\"cuda\")\n",
    "    loader = DataLoader(train_set, batch_size=run.batch_size, shuffle=True)\n",
    "    optimizer = run.op(network.parameters(), lr=run.lr)\n",
    "    sanitized_run = sanitize_for_windows_path(str(run))    # Sanitize run name before calling m.begin_run\n",
    "    m.begin_run(sanitized_run, network, loader)\n",
    "\n",
    "    for epoch in range(run.number_epocs):\n",
    "        list = []\n",
    "        m.begin_epoch()\n",
    "        for batch in train_loader:\n",
    "            characteristics, labels = batch\n",
    "            characteristics, labels = characteristics.to(\"cuda\"), labels.to(\"cuda\")\n",
    "            preds = network(characteristics)  # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels)  # Calculate Loss\n",
    "            optimizer.zero_grad()  # Zero Gradients\n",
    "            loss.backward()  # Calculate Gradients\n",
    "            optimizer.step()  # Update Weights\n",
    "            m.track_loss(loss, batch)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        m.end_epoch()\n",
    "\n",
    "        f = m.epoch_num_correct / len(train_loader.dataset)\n",
    "        list.append(f)\n",
    "        #print(f\"Epoch {epoch + 1}/{run.number_epocs}, Loss: {m.epoch_loss}, Accuracy: {m.epoch_num_correct / len(train_loader.dataset):.4f}\")\n",
    "    #maxy = round_to_sig_figs(np.max(list), 3)\n",
    "    maxy = np.max(list)\n",
    "    print(run, \",\" , \"Accuracy = \", maxy)\n",
    "    max1.append(maxy)\n",
    "    #I = time.time()\n",
    "    #time42.append(I - u_u)\n",
    "    #print(\"Average time\", np.average(time42))\n",
    "    \n",
    "print(\"Maximum accuracy run at row:\", np.argmax(max1)+1,\".)\", np.max(max1))"
   ],
   "id": "9ec1e7d50f09fe2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(lr=0.0151, batch_size=36, number_epocs=1, op=<class 'torch.optim.adamw.AdamW'>) , Accuracy =  0.7206833333333333\n",
      "Maximum accuracy run at row: 1 .) 0.7206833333333333\n"
     ]
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:32:31.479477Z",
     "start_time": "2024-11-29T01:32:31.446926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#saving the CNN network \n",
    "torch.save(network, 'network.pth')\n",
    "help_me = torch.load('network.pth', weights_only = False).to(\"cuda:0\")#, weights_only = True)\n",
    "help_me.eval()  # Set to evaluation mode"
   ],
   "id": "29069298f12c7c40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Down(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc2): Linear(in_features=16, out_features=200, bias=True)\n",
       "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (out): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (fc1): Linear(in_features=3136, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:33:06.849794Z",
     "start_time": "2024-11-29T01:33:06.691510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#testing the trained model\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()]))\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "sample = next(iter(train_loader))\n",
    "image, label = sample\n",
    "\n",
    "image, labels = image.to(\"cuda:0\"), labels.to(\"cuda:0\")\n",
    "image = image.to(\"cuda\")\n",
    "\n",
    "images = image[0].unsqueeze(0)  # From [16, 14, 14] to [1, 16, 14, 14]\n",
    "labels = labels[0].unsqueeze(0)\n",
    "\n",
    "# Plot the first channel of the image\n",
    "plt.imshow(images[0, 0].cpu().numpy(), cmap='gray')  # Visualize the first channel\n",
    "\n",
    "# Pass through the network\n",
    "preds = help_me(images)  # Input shape: [1, 16, 14, 14]\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "holdall = get_num_correct(preds.to('cuda'), labels.to('cuda'))\n",
    "\n",
    "#print to check\n",
    "print(holdall)\n",
    "#print(preds.shape, labels.shape)"
   ],
   "id": "ed2432a9c27eb2b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8e672110118c8100"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
