{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ameoba CNN for the final project",
   "id": "a6ea1c082bcc18a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T21:43:28.103145Z",
     "start_time": "2025-03-08T21:43:24.728129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from itertools import product\n",
    "from collections import OrderedDict, namedtuple\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import csv\n",
    "\n",
    "def sanitize_for_windows_path(name):\n",
    "    # Replace invalid characters with underscores or remove them\n",
    "    invalid_chars = r'<>:\"/\\\\|?*'\n",
    "    return ''.join('_' if c in invalid_chars else c for c in name)"
   ],
   "id": "a93ad49a368c6ad6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T21:43:28.110950Z",
     "start_time": "2025-03-08T21:43:28.107656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img1_directory = \"A:\\\\3rd_Year_Project\\\\Project_code\\\\data\\\\Siamese_dataset\\\\img1.npz\"\n",
    "training_directory = \"A:\\\\3rd_Year_Project\\\\Project_code\\\\data\\\\Siamese_dataset\\\\15.npz\"\n",
    "testing_directory = \"A:\\\\3rd_Year_Project\\\\Project_code\\\\data\\\\Siamese_dataset\\\\2nd.npz\""
   ],
   "id": "3e9d08db52738c57",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T21:43:29.133869Z",
     "start_time": "2025-03-08T21:43:29.128864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to 100x100 pixels # no we want 128x128 idiot, we like 128x128\n",
    "    transforms.ToTensor(),           # Convert to Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] # this does who knows what, probably jsut set's it up correctly\n",
    "])"
   ],
   "id": "d9afcb5791b7f9bd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T21:43:29.150672Z",
     "start_time": "2025-03-08T21:43:29.144687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SiameseNetworkDataset():\n",
    "    def __init__(self, npz_file=None, transform=None): #load dataset from the provided .npz files\n",
    "        self.data = np.load(npz_file) #Extract images form loaded data\n",
    "        self.images = self.data['images'] #Extract labels from the loaded data\n",
    "        self.labels = self.data['labels'] #Extract labels form the loaded data\n",
    "        self.transform = transform #stroe any image transofmation(in .transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        label = self.labels[index] # load the images with their associated label\n",
    "\n",
    "        img = Image.fromarray(img) # convert from numpy array to PIL image\n",
    "\n",
    "        #if self.transform: # apply trransofmation if one exists(one does)\n",
    "        #    img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.float32) # return the transformed image and label as a float tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images) #Return the total number of images in the dataset"
   ],
   "id": "8d97987af650e4c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T21:43:29.175396Z",
     "start_time": "2025-03-08T21:43:29.169063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SiameseNetworkDataset(torch.utils.data.Dataset): #\n",
    "    def __init__(self, img1_dir, img2_dir, transform=None): # preparing the data from the directories\n",
    "        self.img1_data = np.load(img1_dir)\n",
    "        self.img1_images = self.img1_data['images']#loading in all the img1 images\n",
    "        self.img1_labels = self.img1_data['labels'] #loading in allthe img1 labels\n",
    "\n",
    "        self.img2_data = np.load(img2_dir) #loads the second image data\n",
    "        self.img2_images = self.img2_data['images'] #loads the images\n",
    "        self.img2_labels = self.img2_data['labels'] # loads the labels for img2\n",
    "\n",
    "        self.transform = transform # does some funky transformations\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #sample a randomly healthy image from img1 (this is easy as the label is always 0 for healthy)\n",
    "        random_index = np.random.choice(len(self.img1_images)) # randomly loading an inividual image from img1\n",
    "        img1 = Image.fromarray(self.img1_images[random_index]).convert(\"L\") #opens the image as a greyscale(l stands for luminescence or however you spell it)\n",
    "\n",
    "        #time to load img2 and label directly from npz file(either healthy or a guy who visits maccies every day *cough* Niamh)\n",
    "        img2 = self.img2_images[index] # load the image numebred \"index\"\n",
    "        img2 = Image.fromarray(img2).convert(\"L\")  # make img 2 greyscale with some funky stuff I've never seen before but apparently it works\n",
    "\n",
    "        if self.img1_labels[index] == self.img2_labels[index]:\n",
    "\t\t\tlabel = 0\n",
    "\t\telse:\n",
    "\t\t\tlabel = 1 #loading the similarity labels for the images(0 == similar, 1 == different)\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)#transform img 1\n",
    "            img2 = self.transform(img2) # transform img 2\n",
    "\n",
    "        label = torch.tensor(float(label), dtype=torch.float32) # load label of img2 as a\n",
    "        return img1, img2, label # finish this tomfoolery and output this stuff\n",
    "    def __len__(self):#this is supposed to do something, I dont know\n",
    "        return len(self.img2_images)# ok, now I am even more confused, but the code says it works so lets keep it"
   ],
   "id": "f5ce8b13bace9660",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T21:43:29.192836Z",
     "start_time": "2025-03-08T21:43:29.185748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1 # input channels (1 for greyscale)\n",
    "                      , 96 # output channels\n",
    "                      , kernel_size=11,stride=1), #\n",
    "            nn.ReLU(inplace=True), # acticate the function\n",
    "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2), # normalisation to stabalize training\n",
    "            nn.MaxPool2d(3, stride=2), # pooling to reduce spacial dimensions? whatever that means\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2), # 2nd conv layer\n",
    "            nn.ReLU(inplace=True), # activate the layer\n",
    "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2), # normalisation\n",
    "            nn.MaxPool2d(3, stride=2), # pooling\n",
    "            nn.Dropout2d(p=0.3), # dropout to reduceoverfitting\n",
    "\n",
    "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3), # all this stuff is the same as before\n",
    "\n",
    "        )\n",
    "\n",
    "        # Defining the fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(43264, 1024), # input size depends onthe flattened CNN output\n",
    "            nn.ReLU(inplace=True), # activate the funciton\n",
    "            nn.Dropout(p=0.5), # dropout for rgulaisation\n",
    "\n",
    "            nn.Linear(1024, 128), # \"linearise\" it again\n",
    "            nn.ReLU(inplace=True), # activate it\n",
    "\n",
    "            nn.Linear(128, 1)) # originally the was the under bit of this line\n",
    "                      #,2))\n",
    "                            #last nn.linear is to get a distance similarity whatever that means\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        x1 = self.cnn1(img1) # pass both images through the first cnn layer\n",
    "        x2 = self.cnn1(img2)\n",
    "\n",
    "        x1 = x1.view(x1.size(0), -1) # flattten the outputs to a 2d tensor\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "        distance = torch.abs(x1 - x2) # find the absolute difference between the 2 image results\n",
    "        score = self.fc1(distance) # put the distance into the fc layer to find a similarity score\n",
    "        output = torch.sigmoid(score)  # make the output either 0, or 1\n",
    "        return output"
   ],
   "id": "f183b2ad4feaa08e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T21:43:29.207943Z",
     "start_time": "2025-03-08T21:43:29.202793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__() # margin defines minimuin distance for dissimilar pairs\n",
    "        self.bce = nn.BCELoss() # if simimilar pair in the marging hten loss is incurred\n",
    "\n",
    "    def forward(self, output, label):\n",
    "        loss_contrastive = self.bce(output, label)\n",
    "        return loss_contrastive"
   ],
   "id": "908593f9b1290347",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T21:43:29.224364Z",
     "start_time": "2025-03-08T21:43:29.217364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Hyperparameter Search with RunManager and Run Builder\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "        return runs\n",
    "\n",
    "\n",
    "class RunManager():\n",
    "    def save_checkpoint(self, model, optimizer, epoch, filename=\"checkpoint.pth\"):\n",
    "        \"\"\"Save model checkpoint at the current epoch.\"\"\"\n",
    "        print(f\"Saving checkpoint at epoch {epoch}\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, filename)\n",
    "\n",
    "    def validate(self, model, validation_dataloader):\n",
    "        model.eval()  # Switch to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss_history = []\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation for validation\n",
    "            for data in validation_dataloader:\n",
    "                img1, img2, label = data\n",
    "                img1, img2, label = img1.cuda(), img2.cuda(), label.cuda()\n",
    "\n",
    "                output = model(img1, img2).squeeze(1)\n",
    "                loss_contrastive = criterion(output, label)\n",
    "                loss_history.append(loss_contrastive.item())\n",
    "\n",
    "                # Compute accuracy#\n",
    "                #euclidean_distance = F.pairwise_distance(output)\n",
    "                predictions = (output < 0.5).float()\n",
    "                correct += (predictions == label).sum().item()\n",
    "                total += label.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        avg_loss = sum(loss_history) / len(loss_history)\n",
    "        #print(f\"Validation Accuracy: {accuracy*100:.4f}, Avg. Validation Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        return accuracy, avg_loss"
   ],
   "id": "4a4027ec5224a12b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T21:43:29.425949Z",
     "start_time": "2025-03-08T21:43:29.233701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Hyper Parameter search with RunManager\n",
    "#params = OrderedDict( # params for the server\n",
    "    #lr=[0.0025, 0.005, 0.0075],\n",
    "    #batch_size=[8],\n",
    "    #number_epochs=[5],\n",
    "    #op=[torch.optim.AdamW])  # Only store the optimizer class here\n",
    "params = OrderedDict(lr=[0.0001, 0.001, 0.0025, 0.005, 0.0075, 0.001,0.1],\n",
    "\t\t\t\t\t batch_size = [8, 16, 32, 64, 128, 256],\n",
    "\t\t\t\t\t number_epochs=[20],\n",
    "\t\t\t\t\t op=[torch.optim.AdamW, torch.optim.Adam, torch.optim.SGD, torch.optim.RAdam,torch.optim.NAdam])\n",
    "model = SiameseNetwork()\n",
    "\n",
    "m = RunManager()\n",
    "b = RunBuilder.get_runs(params)\n",
    "\n",
    "for run in b:\n",
    "    if run.op == torch.optim.SGD:\n",
    "        optimizer = run.op(model.parameters(), lr=run.lr, weight_decay=0.0005)\n",
    "    else:\n",
    "        optimizer = run.op(model.parameters(), lr=run.lr, eps=1e-8, weight_decay=0.0005)\n",
    "\n",
    "for run in b:\n",
    "    print(run)"
   ],
   "id": "aaa26b93914329fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(lr=0.0001, batch_size=8, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0001, batch_size=8, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0001, batch_size=8, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0001, batch_size=8, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0001, batch_size=8, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0001, batch_size=16, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0001, batch_size=16, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0001, batch_size=16, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0001, batch_size=16, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0001, batch_size=16, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0001, batch_size=32, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0001, batch_size=32, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0001, batch_size=32, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0001, batch_size=32, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0001, batch_size=32, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0001, batch_size=64, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0001, batch_size=64, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0001, batch_size=64, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0001, batch_size=64, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0001, batch_size=64, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0001, batch_size=128, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0001, batch_size=128, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0001, batch_size=128, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0001, batch_size=128, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0001, batch_size=128, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0001, batch_size=256, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0001, batch_size=256, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0001, batch_size=256, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0001, batch_size=256, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0001, batch_size=256, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0025, batch_size=8, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0025, batch_size=8, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0025, batch_size=8, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0025, batch_size=8, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0025, batch_size=8, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0025, batch_size=16, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0025, batch_size=16, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0025, batch_size=16, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0025, batch_size=16, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0025, batch_size=16, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0025, batch_size=32, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0025, batch_size=32, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0025, batch_size=32, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0025, batch_size=32, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0025, batch_size=32, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0025, batch_size=64, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0025, batch_size=64, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0025, batch_size=64, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0025, batch_size=64, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0025, batch_size=64, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0025, batch_size=128, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0025, batch_size=128, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0025, batch_size=128, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0025, batch_size=128, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0025, batch_size=128, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0025, batch_size=256, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0025, batch_size=256, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0025, batch_size=256, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0025, batch_size=256, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0025, batch_size=256, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.005, batch_size=8, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.005, batch_size=8, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.005, batch_size=8, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.005, batch_size=8, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.005, batch_size=8, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.005, batch_size=16, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.005, batch_size=16, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.005, batch_size=16, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.005, batch_size=16, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.005, batch_size=16, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.005, batch_size=32, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.005, batch_size=32, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.005, batch_size=32, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.005, batch_size=32, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.005, batch_size=32, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.005, batch_size=64, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.005, batch_size=64, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.005, batch_size=64, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.005, batch_size=64, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.005, batch_size=64, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.005, batch_size=128, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.005, batch_size=128, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.005, batch_size=128, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.005, batch_size=128, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.005, batch_size=128, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.005, batch_size=256, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.005, batch_size=256, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.005, batch_size=256, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.005, batch_size=256, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.005, batch_size=256, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0075, batch_size=8, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0075, batch_size=8, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0075, batch_size=8, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0075, batch_size=8, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0075, batch_size=8, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0075, batch_size=16, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0075, batch_size=16, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0075, batch_size=16, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0075, batch_size=16, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0075, batch_size=16, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0075, batch_size=32, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0075, batch_size=32, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0075, batch_size=32, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0075, batch_size=32, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0075, batch_size=32, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0075, batch_size=64, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0075, batch_size=64, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0075, batch_size=64, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0075, batch_size=64, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0075, batch_size=64, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0075, batch_size=128, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0075, batch_size=128, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0075, batch_size=128, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0075, batch_size=128, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0075, batch_size=128, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.0075, batch_size=256, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.0075, batch_size=256, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.0075, batch_size=256, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.0075, batch_size=256, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.0075, batch_size=256, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=8, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=16, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=32, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=64, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=128, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.001, batch_size=256, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.1, batch_size=8, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.1, batch_size=8, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.1, batch_size=8, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.1, batch_size=8, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.1, batch_size=8, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.1, batch_size=16, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.1, batch_size=16, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.1, batch_size=16, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.1, batch_size=16, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.1, batch_size=16, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.1, batch_size=32, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.1, batch_size=32, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.1, batch_size=32, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.1, batch_size=32, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.1, batch_size=32, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.1, batch_size=64, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.1, batch_size=64, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.1, batch_size=64, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.1, batch_size=64, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.1, batch_size=64, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.1, batch_size=128, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.1, batch_size=128, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.1, batch_size=128, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.1, batch_size=128, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.1, batch_size=128, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n",
      "Run(lr=0.1, batch_size=256, number_epochs=20, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "Run(lr=0.1, batch_size=256, number_epochs=20, op=<class 'torch.optim.adam.Adam'>)\n",
      "Run(lr=0.1, batch_size=256, number_epochs=20, op=<class 'torch.optim.sgd.SGD'>)\n",
      "Run(lr=0.1, batch_size=256, number_epochs=20, op=<class 'torch.optim.radam.RAdam'>)\n",
      "Run(lr=0.1, batch_size=256, number_epochs=20, op=<class 'torch.optim.nadam.NAdam'>)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:06:50.880876Z",
     "start_time": "2025-03-08T18:06:49.845256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset from raw image folders\n",
    "\n",
    "siamese_dataset = SiameseNetworkDataset(\n",
    "    img1_dir=r\"A:/3rd_Year_Project/Project_code/data/Siamese_dataset/img1.npy\", #Directory containing the first set of images(anchor images)\n",
    "    img2_dir=training_directory, # derecotry containing hte second set of images(comparision images)\n",
    "    transform=transforms.Compose([ #Defie image transformations\n",
    "        transforms.Resize((128, 128)), # resize to 128x128 pixels\n",
    "        transforms.ToTensor()])) # convert images to pytorch tensors\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(siamese_dataset, # loading inthe siamese dataset defined above\n",
    "                              shuffle=True, #shuffle for training to randomise things\n",
    "                              num_workers=0, # no. parralllel processes\n",
    "                              batch_size=run.batch_size, # set a batch size\n",
    "                              pin_memory= True) # pinmemory to speed up data transfer to the gpu"
   ],
   "id": "a630e8c6432c4b29",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:06:51.649783Z",
     "start_time": "2025-03-08T18:06:50.885393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define validation dataset\n",
    "val_dataset = SiameseNetworkDataset(img1_directory, #Directory containing the first set of images(anchor images)\n",
    "                                    testing_directory, # derecotry containing hte second set of images(comparision images)\n",
    "                                    transform=transforms.Compose([ #Defie image transformations\n",
    "                                        transforms.Resize((128, 128)), # resize to 128x128 pixels\n",
    "                                        transforms.ToTensor() # convert images to pytorch tensors\n",
    "                                    ]))\n",
    "\n",
    "# Create DataLoader using val_dataset\n",
    "validation_dataloader = DataLoader(val_dataset, # dataset to lead from (defined above)\n",
    "                                   shuffle=False, # No need to shefful for validation\n",
    "                                   num_workers=0, # Number of parralel processes(1 thread)\n",
    "                                   batch_size=run.batch_size, # Number of samples per batch, defined in training config\n",
    "                                   pin_memory=True) # pin memory to speed up data transfer to gpu (reccommended when using Cuda)"
   ],
   "id": "f5ef7d559957197f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:06:53.650164Z",
     "start_time": "2025-03-08T18:06:53.642446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#def train():\n",
    "def train(net, train_loader, criterion, optimizer, device, number_epochs = run.number_epochs):\n",
    "    total_batches_seen = 1\n",
    "    total_batches = len(train_dataloader) * number_epochs\n",
    "    start_train = time.time()\n",
    "\n",
    "    net.to(device) # movethe model to the device\n",
    "\n",
    "    #for final graph\n",
    "    epoch_number = 1\n",
    "    counter = []\n",
    "    loss_history = []\n",
    "    epoch_acc = []\n",
    "\n",
    "    optimizer = run.op(net.parameters(), lr=run.lr) # initialise the optimizer from the run object\n",
    "\n",
    "    for epoch in range(number_epochs): # loop over all epochs\n",
    "        total_samples = 0\n",
    "\n",
    "        net.train() # set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "\n",
    "        for batch_idx,(img1, img2, label) in enumerate(train_dataloader): # get a pair of images and their similatiry, 0 for same, 1 for differnet, label is the label for img2\n",
    "            current_iter = epoch * len(train_dataloader) + batch_idx + 1\n",
    "\n",
    "            img1, img2, label = img1.cuda(), img2.cuda(), label.cuda() # load to gpu\n",
    "\n",
    "            optimizer.zero_grad() # resets gradients for this batch\n",
    "            output = net(img1, img2).squeeze(1) # output should be similarity score (ideally 0 = similar, 1 = different)\n",
    "            loss_contrastive = criterion(output, label) # find loss between predicted similarity score and true label\n",
    "            loss_contrastive.backward()  #backpropogate the loss to compute the gradients\n",
    "            optimizer.step() # update modeel parameters using computated gradients\n",
    "\n",
    "            running_loss += loss_contrastive.item() # track the running loss\n",
    "\n",
    "            end_batch = time.time()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predicted = (output < 0.5).float()  # similarity scores < 0.5 = similar (label 0)\n",
    "            correct += (predicted == label).sum().item()  # count how many predictions matched the label\n",
    "            accuracy1 = correct / total_batches_seen\n",
    "\n",
    "            total_samples += label.size(0)\n",
    "\n",
    "            #if total_batches_seen % 1000 == 0 or total_batches_seen in{10} :\n",
    "            if total_batches_seen == 10:\n",
    "                elapsed_time = end_batch - start_train\n",
    "                mean_time_per_batch = elapsed_time / total_batches_seen\n",
    "                batches_left = total_batches - (batch_idx + 1 + epoch * len(train_dataloader))\n",
    "\n",
    "                progress_fraction =current_iter / total_batches\n",
    "\n",
    "                remaining_time = batches_left * mean_time_per_batch\n",
    "                hours = int(remaining_time // 3600)\n",
    "                minutes = int((remaining_time % 3600) // 60)\n",
    "                seconds = int(remaining_time % 60)\n",
    "\n",
    "                print(f\"We are {progress_fraction * 100:.2f}% complete. ETA: {hours}h {minutes}m {seconds}s\")\n",
    "\n",
    "            total_batches_seen += 1\n",
    "\n",
    "        # Compute and store accuracy for the epoch\n",
    "        epoch_acc.append(accuracy1 * 100)\n",
    "        counter.append(epoch_number)\n",
    "        epoch_number += 1#add one to the current value of epoch_number\n",
    "        loss_history.append(running_loss)\n",
    "\n",
    "    plt.plot(counter, loss_history, label = \"Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "    return net, counter, loss_history, epoch_acc #return trained model after all epochs are complete"
   ],
   "id": "38a10741a82bfd63",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-07T22:55:46.303723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#imitialiseparameters to trackbest model and corresponding optimiser\n",
    "best_validation_accuracy = 0.0#track highest validation accuracy seen\n",
    "best_model = None #stores best perfoming model\n",
    "best_optimizer = None # stores optimiser for said model\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "net = SiameseNetwork().cuda() # create fresh instance fo the Siamese netowrk and move to gpu\n",
    "criterion = ContrastiveLoss() # set up loss function(stays same for all runs\n",
    "\n",
    "#save to csv stuff\n",
    "Epoch_num = []\n",
    "ETA_list = []\n",
    "Accuracy_list = []\n",
    "Loss_list = []\n",
    "learning_rate_list = []\n",
    "Batch_size_list = []\n",
    "\n",
    "start_whole_run = time.time()\n",
    "total_parameters = len(b)\n",
    "total_parameters_trained = 0\n",
    "\n",
    "#loop through all hyperparameter combinations\n",
    "for run in b:\n",
    "    total_parameters_trained += 1\n",
    "    print(f\"Running hyperparameter set: {run}\") # print the hyperparameters being used\n",
    "\n",
    "    # Create DataLoader with the specified batch size\n",
    "    train_dataloader = torch.utils.data.DataLoader(siamese_dataset, batch_size=run.batch_size, shuffle=True) #create the training set usingthe hyperparameters\n",
    "    validation_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=run.batch_size, shuffle=False)#create calidation set for curent hyperparameters\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    model = SiameseNetwork()\n",
    "    model = model.cuda()  # Move to GPU if available\n",
    "    optimizer = run.op(model.parameters(), lr=run.lr)\n",
    "\n",
    "    # Train the model\n",
    "    pre_train_time = time.time()\n",
    "    model, counter, loss_history, epoch_acc = train(model, train_dataloader, criterion, optimizer, device = torch.device(\"cuda:0\"))\n",
    "    post_train_time = time.time()\n",
    "\n",
    "    total_time = post_train_time - pre_train_time\n",
    "\n",
    "    # Validate the model\n",
    "    accuracy, avg_loss = m.validate(model, validation_dataloader) # should return the accuracy and average loss for the validation data\n",
    "\n",
    "    #save all the data as a csv for further optimisation to make my life easier\n",
    "    #Epoch_num.append(counter)\n",
    "    Epoch_num.append(run.number_epochs)\n",
    "    ETA_list.append(total_time)\n",
    "    Accuracy_list.append(epoch_acc[-1])\n",
    "    Loss_list.append(loss_history[-1])\n",
    "    Batch_size_list.append(run.batch_size)\n",
    "    learning_rate_list.append(run.lr)\n",
    "\n",
    "    # Save the best model\n",
    "    if accuracy > best_validation_accuracy: # if current model better than previous model then append to\n",
    "        best_validation_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_optimizer = optimizer\n",
    "        filename = f\"best_model_run_lr{run.lr}_bs{run.batch_size}_epochs{run.number_epochs}.pth\"\n",
    "        m.save_checkpoint(model, optimizer, run.number_epochs, filename=filename) # save the best performing models checkpoint\n",
    "\n",
    "    end_parameter_set = time.time()\n",
    "    time_per_run = (end_parameter_set - start_whole_run)/total_parameters_trained\n",
    "    runs_left = total_parameters - total_parameters_trained\n",
    "    time_remaining = time_per_run * runs_left\n",
    "\n",
    "#print(f\"Best Validation Accuracy: {best_validation_accuracy:.4f}\")\n",
    "\n",
    "#save to csv\n",
    "headers = [\"Epoch Number\", \"ETA\", \"Accuracy\", \"Loss\", \"Learning Rate\", \"Batch Size\"]\n",
    "rows = zip(Epoch_num, ETA_list, Accuracy_list, Loss_list, learning_rate_list, Batch_size_list)\n",
    "csv_path = r\"A:\\3rd_Year_Project\\Project_code\\data\\Optimisation data\\Optimisation data.csv\"\n",
    "\n",
    "# Write to CSV in the target directory\n",
    "with open(csv_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers first\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Write data rows\n",
    "    writer.writerows(rows)\n",
    "# Print preview (like how it will look in a CSV)\n",
    "print(\",\".join(headers))  # Print headers first\n",
    "for row in rows:\n",
    "    print(\",\".join(map(str, row)))  # Convert each item to string and print as CSV row"
   ],
   "id": "6c00bada777f0b54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hyperparameter set: Run(lr=0.0025, batch_size=8, number_epochs=5, op=<class 'torch.optim.adamw.AdamW'>)\n",
      "We are 0.13% complete. ETA: 0h 49m 34s\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b47326006d3df60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
